## М Transformaciones y L贸gica

###  Preparaci贸n de datos

- Se gener贸 un conjunto de datos bidimensionales sint茅ticos para facilitar la visualizaci贸n de los clusters.
- Se estandarizaron las variables con `StandardScaler` para evitar sesgos por escala.
- Se aplic贸 una validaci贸n visual previa para detectar posibles agrupamientos naturales.

---

###  Algoritmos de clustering aplicados

####  K-Means
- Se entren贸 el modelo con distintos valores de `k` (n煤mero de clusters).
- Se utiliz贸 el m茅todo del codo (`KElbowVisualizer`) para determinar el valor 贸ptimo de `k`.
- Se evalu贸 la cohesi贸n de los clusters con el coeficiente de silueta (`SilhouetteVisualizer`).
- Se graficaron los clusters resultantes con colores diferenciados y centroides marcados.

####  DBSCAN
- Se aplic贸 el algoritmo con distintos valores de `eps` y `min_samples`.
- Se identificaron clusters de forma arbitraria y puntos considerados ruido.
- Se compar贸 la sensibilidad del modelo frente a densidades variables.

---

###  M茅tricas y visualizaciones

- **Coeficiente de silueta**: se utiliz贸 para evaluar la separaci贸n entre clusters.
- **Gr谩ficos de dispersi贸n**: se emplearon para visualizar los agrupamientos y comparar resultados entre algoritmos.
- **Visualizadores de Yellowbrick**: facilitaron la interpretaci贸n de m茅tricas y la elecci贸n de par谩metros 贸ptimos.

---

###  Conclusiones

- K-Means funciona bien en datos con forma esf茅rica y distribuci贸n homog茅nea.
- DBSCAN es m谩s robusto frente a ruido y formas arbitrarias, pero sensible a la elecci贸n de `eps`.
- La combinaci贸n de visualizaci贸n + m茅tricas permite tomar decisiones m谩s informadas sobre el modelo a aplicar.